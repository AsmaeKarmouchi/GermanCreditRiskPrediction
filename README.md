# Projet MLOps  - GermanCredit Risk Prediction

##  Vue d'ensemble

Ce projet constitue une **pipeline MLOps   ** pour la prÃ©diction du risque de crÃ©dit basÃ©e sur le dataset German Credit. Il implÃ©mente les meilleures pratiques de l'industrie avec monitoring avancÃ©, API de production, et dashboard interactif.

##  FonctionnalitÃ©s Principales

###  MLOps & Engineering
- **Pipeline automatisÃ©e** avec DVC pour la reproductibilitÃ©
- **Feature engineering avancÃ©** avec crÃ©ation automatique de variables mÃ©tier
- **Hyperparameter tuning** avec recherche alÃ©atoire et validation croisÃ©e
- **Ensemble learning** avec multiple algorithmes (RF, Gradient Boosting, SVM, Logistic Regression)
- **Configuration centralisÃ©e** avec gestion d'environnements
- **Logging structurÃ©** avec niveaux multiples et persistence

###  ModÃ©lisation AvancÃ©e
- **Multiple algorithmes** avec sÃ©lection automatique du meilleur
- **Calibration des probabilitÃ©s** pour des prÃ©dictions fiables
- **MÃ©triques mÃ©tier** (coÃ»t, profit, seuil optimal)
- **Validation robuste** avec stratified k-fold
- **DÃ©tection d'outliers** avec mÃ©thodes IQR et Z-score
- **StabilitÃ© des prÃ©dictions** avec analyse statistique

###  Monitoring & Ã‰valuation
- **MÃ©triques complÃ¨tes** : ROC-AUC, Precision, Recall, F1, mÃ©triques mÃ©tier
- **Visualisations avancÃ©es** : courbes ROC/PR, matrices de confusion, calibration
- **Monitoring temps rÃ©el** avec collecte de mÃ©triques
- **Comparaison de modÃ¨les** automatique
- **Drift detection** (prÃªt Ã  implÃ©menter)

###  Production & DÃ©ploiement
- **API RESTful** avec Flask pour les prÃ©dictions en temps rÃ©el
- **Batch predictions** pour traitement en lot
- **Health checks** et monitoring API
- **Dashboard interactif** Streamlit pour le monitoring
- **Tests complets** avec unittest et couverture de code

##  Architecture

```
 GermanCreditRiskPrediction/
â”œâ”€â”€  api/                     # API de prÃ©diction
â”‚   â””â”€â”€ prediction_api.py       # API Flask avec monitoring
â”œâ”€â”€  config/                  # Configuration centralisÃ©e
â”‚   â””â”€â”€ config.py               # Classes de configuration
â”œâ”€â”€  dashboard/               # Dashboard de monitoring
â”‚   â””â”€â”€ ml_dashboard.py         # Dashboard Streamlit interactif
â”œâ”€â”€  data/
â”‚   â”œâ”€â”€  raw/                 # DonnÃ©es brutes
â”‚   â”œâ”€â”€  processed/           # DonnÃ©es preprocessÃ©es
â”‚   â””â”€â”€  features/            # Feature store
â”œâ”€â”€  models/                  # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€  notebooks/               # Notebooks d'exploration
â”œâ”€â”€  reports/                 # Rapports et visualisations
â”‚   â”œâ”€â”€  figures/             # Graphiques gÃ©nÃ©rÃ©s
â”‚   â””â”€â”€  metrics/             # MÃ©triques sauvegardÃ©es
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€  data/                # Scripts de donnÃ©es
â”‚   â”œâ”€â”€  features/            # Feature engineering avancÃ©
â”‚   â”‚   â””â”€â”€ advanced_features.py
â”‚   â”œâ”€â”€  models/              # ModÃ©lisation avancÃ©e
â”‚   â”‚   â”œâ”€â”€ advanced_training.py    # EntraÃ®nement avec ensemble
â”‚   â”‚   â””â”€â”€ advanced_evaluation.py # Ã‰valuation complÃ¨te
â”‚   â””â”€â”€  visualization/       # Visualisations
â”œâ”€â”€  tests/                   # Tests complets
â”‚   â””â”€â”€ test_ml_pipeline.py     # Tests d'intÃ©gration
â”œâ”€â”€  utils/                   # Utilitaires
â”‚   â””â”€â”€ logging_utils.py        # Logging et MLFlow
â”œâ”€â”€  dvc.yaml                 # Pipeline DVC
â”œâ”€â”€  params.yaml              # Configuration des hyperparamÃ¨tres
â””â”€â”€  requirements.txt         # DÃ©pendances

```

## DÃ©marrage Rapide

### 1. Installation des dÃ©pendances
```bash
pip install -r requirements.txt
```

### 2. Configuration de l'environnement
```bash
# Initialiser DVC
dvc init

# Configurer MLFlow (optionnel)
mlflow ui  # Lance l'interface MLFlow
```

### 3. ExÃ©cution du pipeline complet
```bash
# Pipeline automatique avec DVC
dvc repro

# Ou exÃ©cution manuelle Ã©tape par Ã©tape
python src/data/download.py
python src/features/advanced_features.py
python src/models/advanced_training.py
python src/models/advanced_evaluation.py
```

### 4. Lancement des services

#### API de prÃ©diction
```bash
python api/prediction_api.py
# Accessible sur http://localhost:5000
```

#### Dashboard de monitoring
```bash
streamlit run dashboard/ml_dashboard.py
# Accessible sur http://localhost:8501
```

## ðŸ“Š Utilisation de l'API

### PrÃ©diction unique
```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "duration": 24,
    "amount": 5000,
    "age": 35,
    "status": "0 <= ... < 200 DM"
  }'
```

### PrÃ©diction par lot
```bash
curl -X POST http://localhost:5000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      {"duration": 24, "amount": 5000, "age": 35},
      {"duration": 12, "amount": 2000, "age": 28}
    ]
  }'
```

### Health check
```bash
curl http://localhost:5000/health
```

##  Tests

```bash
# ExÃ©cuter tous les tests
python -m pytest tests/ -v

# Tests avec couverture
python -m pytest tests/ --cov=src --cov-report=html

# Tests spÃ©cifiques
python tests/test_ml_pipeline.py
```

##  MÃ©triques et Monitoring

### MÃ©triques Techniques
- **Accuracy, Precision, Recall, F1-Score**
- **ROC-AUC, Average Precision**
- **Specificity, NPV**

### MÃ©triques MÃ©tier
- **CoÃ»t total des erreurs**
- **Ã‰conomies rÃ©alisÃ©es**
- **Seuil optimal de dÃ©cision**
- **Taux d'acceptation optimal**

### Monitoring Temps RÃ©el
- **Latence des prÃ©dictions**
- **Taux d'erreur**
- **Distribution des prÃ©dictions**
- **StabilitÃ© du modÃ¨le**

##  Configuration AvancÃ©e

### HyperparamÃ¨tres (params.yaml)
```yaml
train:
  test_size: 0.2
  random_state: 42

preprocessing:
  outlier_method: "iqr"
  scaling_method: "standard"
  feature_selection: true

hyperparameter_tuning:
  n_trials: 50
  optimization_method: "random_search"

monitoring:
  performance_threshold: 0.85
  drift_detection: true
```

### Variables d'environnement
```bash
# MLFlow tracking
export MLFLOW_TRACKING_URI=sqlite:///mlflow.db

# Logging level
export LOG_LEVEL=INFO

# API configuration
export API_HOST=0.0.0.0
export API_PORT=5000
```

##  AmÃ©liorations 

### Code Quality
-  **Architecture modulaire** avec sÃ©paration des responsabilitÃ©s
-  **Configuration centralisÃ©e** vs hardcodage
-  **Logging structurÃ©** vs print statements
-  **Gestion d'erreurs robuste** avec try/catch appropriÃ©s
-  **Documentation complÃ¨te** avec docstrings
-  **Type hints** pour la clartÃ© du code

### ML Engineering
-  **Feature engineering automatisÃ©** vs manuel
-  **Multiple algorithmes** vs un seul RandomForest
-  **Hyperparameter tuning** vs paramÃ¨tres fixes
-  **Ensemble learning** vs modÃ¨le unique
-  **Validation croisÃ©e stratifiÃ©e** vs simple train/test
-  **Calibration des probabilitÃ©s** vs prÃ©dictions brutes

### Production Ready
-  **API RESTful complÃ¨te** vs script isolÃ©
-  **Monitoring et mÃ©triques** vs pas de suivi
-  **Dashboard interactif** vs pas de visualisation
-  **Tests automatisÃ©s** vs pas de tests
-  **Pipeline reproductible** avec DVC
-  **DÃ©ploiement containerisÃ©** ready

### Business Impact
-  **MÃ©triques mÃ©tier** (coÃ»t, profit) vs mÃ©triques techniques uniquement
-  **Optimisation de seuil** pour le business
-  **Analyse de rentabilitÃ©** intÃ©grÃ©e
-  **Monitoring de la dÃ©rive** pour la maintenance

##  Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/amazing-feature`)
3. Commit les changements (`git commit -m 'Add amazing feature'`)
4. Push vers la branche (`git push origin feature/amazing-feature`)
5. Ouvrir une Pull Request


## Remerciements

- Dataset German Credit de UCI ML Repository
- Outils open source utilisÃ©s : scikit-learn, MLFlow, DVC, Streamlit

